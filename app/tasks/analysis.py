import logging
import os
import re
import sys
import time
import json
import unicodedata
from datetime import datetime, timedelta
import random
from playwright.sync_api import sync_playwright, Error as PlaywrightError

# --- ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã®å®šç¾© ---
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# --- ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ ---
sys.path.insert(0, PROJECT_ROOT)
from app.utils.selector_utils import convert_to_robust_selector

# --- DB/å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å®šç¾© ---
DB_DIR = os.path.join(PROJECT_ROOT, "db")
OUTPUT_DIR = os.path.join(PROJECT_ROOT, "output")

# --- è¨­å®š ---
TARGET_URL = "https://room.rakuten.co.jp/items"
DB_JSON_FILE = "engagement_data.json"
COMMENT_TEMPLATES_FILE = os.path.join(PROJECT_ROOT, "comment_templates.json")

# --- ãƒ­ã‚¬ãƒ¼ã®åŸºæœ¬è¨­å®š ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def extract_natural_name(full_name: str) -> str:
    """
    çµµæ–‡å­—ã‚„è£…é£¾ãŒå«ã¾ã‚Œã‚‹å¯èƒ½æ€§ã®ã‚ã‚‹ãƒ•ãƒ«ãƒãƒ¼ãƒ ã‹ã‚‰ã€è‡ªç„¶ãªåå‰ã®éƒ¨åˆ†ã‚’æŠ½å‡ºã™ã‚‹ã€‚
    ä¾‹: 'æ˜¥ğŸŒ·èº«é•·ãŒ3cmä¼¸ã³ã¾ã—ãŸğŸ˜³' -> 'æ˜¥'
    ä¾‹: 'ğ¬ğšğ²ğ®Â¹Â²Â²âµğ“¡' -> 'sayu'
    ä¾‹: 'âmizukiâ' -> 'mizuki'
    """
    if not full_name:
        return ""

    # Unicodeã®çµµæ–‡å­—ã‚„ç‰¹å®šã®è¨˜å·ã‚’åŒºåˆ‡ã‚Šæ–‡å­—ã¨ã—ã¦å®šç¾©
    separators = re.compile(
        r'['
        u'\u2600-\u27BF'          # Miscellaneous Symbols
        u'\U0001F300-\U0001F5FF'  # Miscellaneous Symbols and Pictographs
        u'\U0001F600-\U0001F64F'  # Emoticons
        u'\U0001F680-\U0001F6FF'  # Transport & Map Symbols
        u'\U0001F1E0-\U0001F1FF'  # Flags (iOS)
        u'\U0001F900-\U0001F9FF'  # Supplemental Symbols and Pictographs
        u'|â”‚ï¿¤ï¼ @/ï½œ*ï¼Šâ€»â˜†â˜…â™ª#ï¼ƒâ™­ğŸ€' # å…¨è§’ãƒ»åŠè§’ã®è¨˜å·é¡
        u'|â”‚ï¿¤ï¼ @/ï½œ*ï¼Šâ€»â˜†â˜…â™ª#ï¼ƒâ™­ğŸ€' # å…¨è§’ãƒ»åŠè§’ã®è¨˜å·é¡ï¼ˆâ™¡ã¯æ„å›³çš„ã«é™¤å¤–ï¼‰
        u']+' # é€£ç¶šã™ã‚‹åŒºåˆ‡ã‚Šæ–‡å­—ã‚’ä¸€ã¤ã¨ã—ã¦æ‰±ã†
    )

    # åŒºåˆ‡ã‚Šæ–‡å­—ã§æ–‡å­—åˆ—ã‚’åˆ†å‰²
    parts = separators.split(full_name)

    # åˆ†å‰²ã•ã‚ŒãŸãƒ‘ãƒ¼ãƒ„ã‹ã‚‰ã€ç©ºã§ãªã„æœ€åˆã®è¦ç´ ã‚’æ¢ã™
    # åˆ†å‰²ã•ã‚ŒãŸãƒ‘ãƒ¼ãƒ„ã‹ã‚‰ã€ç©ºã§ãªã„æœ€åˆã®è¦ç´ ã‚’å€™è£œã¨ã™ã‚‹
    name_candidate = ""
    for part in parts:
        cleaned_part = part.strip()
        if cleaned_part:
            return cleaned_part
            name_candidate = cleaned_part
            break
    
    if not name_candidate:
        return full_name.strip() # å€™è£œãŒè¦‹ã¤ã‹ã‚‰ãªã‘ã‚Œã°å…ƒã®åå‰ã‚’è¿”ã™

    # é©åˆ‡ãªãƒ‘ãƒ¼ãƒ„ãŒè¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸå ´åˆï¼ˆåå‰å…¨ä½“ãŒè¨˜å·ã ã£ãŸå ´åˆãªã©ï¼‰ã€å…ƒã®åå‰ã‚’ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¨ã—ã¦è¿”ã™
    return full_name.strip()
    # å€™è£œã®æ–‡å­—åˆ—ã‚’æ­£è¦åŒ– (ä¾‹: ğ¬ğšğ²ğ®Â¹Â²Â²âµğ“¡ -> sayu1225R)
    normalized_name = unicodedata.normalize('NFKC', name_candidate)

    # æ­£è¦åŒ–ã•ã‚ŒãŸåå‰ã‹ã‚‰ã€æœ€åˆã®æ•°å­—ã‚„ç‰¹å®šã®è¨˜å·ã¾ã§ã®éƒ¨åˆ†ã‚’æŠ½å‡º
    match = re.search(r'[\d_â€-]', normalized_name)
    if match:
        return normalized_name[:match.start()]
    
    return normalized_name

def get_latest_timestamp_from_db(db_path: str) -> datetime:
    """
    DBãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æœ€ã‚‚æ–°ã—ã„latest_action_timestampã‚’datetimeã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¨ã—ã¦å–å¾—ã™ã‚‹ã€‚
    """
    latest_timestamp = datetime.min # æ¯”è¼ƒç”¨ã®éå¸¸ã«å¤ã„æ—¥æ™‚ã§åˆæœŸåŒ–
    if not os.path.exists(db_path):
        return latest_timestamp

    try:
        with open(db_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        if not data:
            return latest_timestamp

        for item in data:
            ts_str = item.get('latest_action_timestamp')
            if ts_str:
                ts_dt = datetime.strptime(ts_str, '%Y-%m-%d %H:%M:%S')
                if ts_dt > latest_timestamp:
                    latest_timestamp = ts_dt
    except (json.JSONDecodeError, FileNotFoundError) as e:
        logging.warning(f"DBãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ä¸­ã«è»½å¾®ãªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    
    return latest_timestamp

def main():
    """
    æ¥½å¤©ROOMã®ãŠçŸ¥ã‚‰ã›ãƒšãƒ¼ã‚¸ã‹ã‚‰ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã™ã‚‹ãƒ¡ã‚¤ãƒ³é–¢æ•°
    """
    with sync_playwright() as p:
        # --- 1. ãƒ–ãƒ©ã‚¦ã‚¶ã®èµ·å‹• ---
        logging.info("ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã§èµ·å‹•ä¸­ã®Chrome (ãƒãƒ¼ãƒˆ9222) ã«æ¥ç¶šã—ã¾ã™ã€‚")
        browser = None
        for i in range(5):
            try:
                browser = p.chromium.connect_over_cdp("http://localhost:9222")
                logging.info("Chromeã¸ã®æ¥ç¶šã«æˆåŠŸã—ã¾ã—ãŸã€‚")
                break
            except Exception:
                logging.warning(f"æ¥ç¶šã«å¤±æ•—ã—ã¾ã—ãŸã€‚3ç§’å¾Œã«å†è©¦è¡Œã—ã¾ã™... ({i+1}/5)")
                time.sleep(3)

        if not browser:
            logging.error("Chromeã¸ã®æ¥ç¶šã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            logging.error("ã‚¢ãƒ—ãƒªãŒèµ·å‹•ã—ãŸChromeã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’é–‰ã˜ãšã«ã€ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
            return

        try:
            context = browser.contexts[0]
            page = context.new_page()

            # --- 2. ãƒšãƒ¼ã‚¸é·ç§» ---
            logging.info(f"{TARGET_URL} ã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã¾ã™ã€‚")
            page.goto(TARGET_URL, wait_until="domcontentloaded")

            logging.info("ã€ŒãŠçŸ¥ã‚‰ã›ã€ãƒªãƒ³ã‚¯ã‚’æ¢ã—ã¦ã‚¯ãƒªãƒƒã‚¯ã—ã¾ã™ã€‚")
            page.get_by_role("link", name="ãŠçŸ¥ã‚‰ã›").click()

            page.wait_for_load_state("domcontentloaded", timeout=15000)
            logging.info(f"ãŠçŸ¥ã‚‰ã›ãƒšãƒ¼ã‚¸ã«é·ç§»ã—ã¾ã—ãŸ: {page.url}")

            # --- 3. ç„¡é™ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã«ã‚ˆã‚‹æƒ…å ±åé›† ---
            logging.info("ã€Œã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã—ã¦æƒ…å ±ã‚’åé›†ã—ã¾ã™ã€‚")
            activity_title_locator = page.locator("div.title[ng-show='notifications.activityNotifications.length > 0']")
            try:
                activity_title_locator.wait_for(state='attached', timeout=10000)
            except Exception:
                logging.info("ã€Œã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚å‡¦ç†å¯¾è±¡ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
                return

            logging.info("é…å»¶èª­ã¿è¾¼ã¿ã•ã‚Œã‚‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’è¡¨ç¤ºã™ã‚‹ãŸã‚ã€ãƒšãƒ¼ã‚¸ã‚’ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã—ã¾ã™ã€‚")
            last_count = 0
            for attempt in range(4):
                notification_list_items = page.locator("li[ng-repeat='notification in notifications.activityNotifications']")
                current_count = notification_list_items.count()

                if attempt > 2 and current_count == last_count:
                    logging.info("ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã—ã¦ã‚‚æ–°ã—ã„ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£é€šçŸ¥ã¯èª­ã¿è¾¼ã¾ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
                    break

                last_count = current_count
                logging.info(f"  ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ« {attempt + 1}å›ç›®: {current_count}ä»¶ã®ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£é€šçŸ¥ã‚’æ¤œå‡ºã€‚")
                page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
                page.wait_for_timeout(1500)

            # --- 4. ãƒ‡ãƒ¼ã‚¿æŠ½å‡º ---
            logging.info(f"--- ãƒ•ã‚§ãƒ¼ã‚º1: {notification_list_items.count()}ä»¶ã®é€šçŸ¥ã‹ã‚‰åŸºæœ¬æƒ…å ±ã‚’åé›†ã—ã¾ã™ã€‚ ---")
            all_notifications = []
            for item in notification_list_items.all():
                try:
                    user_name_element = item.locator("span.notice-name span.strong").first
                    if not user_name_element.is_visible():
                        continue

                    user_name = user_name_element.inner_text().strip()
                    profile_image_url = item.locator("div.left-img img").get_attribute("src")

                    if "img_noprofile.gif" in profile_image_url:
                        continue

                    if user_name:
                        user_id = "unknown"
                        match = re.search(r'/([^/]+?)(?:\.\w+)?(?:\?.*)?$', profile_image_url)
                        if match: user_id = match.group(1)

                        action_text = item.locator("div.right-text > p").first.inner_text()
                        action_timestamp = item.locator("span.notice-time").first.get_attribute("title")
                        is_following = not item.locator("span.follow:has-text('æœªãƒ•ã‚©ãƒ­ãƒ¼')").is_visible()

                        all_notifications.append({
                            'id': user_id, 'name': user_name.strip(),
                            'profile_image_url': profile_image_url,
                            'action_text': action_text,
                            'action_timestamp': action_timestamp,
                            'is_following': is_following
                        })
                except Exception as item_error:
                    logging.warning(f"é€šçŸ¥ã‚¢ã‚¤ãƒ†ãƒ ã®å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {item_error}")

            # --- ãƒ•ã‚§ãƒ¼ã‚º2: ãƒ¦ãƒ¼ã‚¶ãƒ¼å˜ä½ã§æƒ…å ±ã‚’é›†ç´„ã—ã€ã‚«ãƒ†ã‚´ãƒªã‚’ä»˜ä¸ ---
            logging.info(f"--- ãƒ•ã‚§ãƒ¼ã‚º2: {len(all_notifications)}ä»¶ã®é€šçŸ¥ã‚’ãƒ¦ãƒ¼ã‚¶ãƒ¼å˜ä½ã§é›†ç´„ã—ã¾ã™ã€‚ ---")
            aggregated_users = {}
            for notification in all_notifications:
                user_id = notification['id']
                if user_id not in aggregated_users:
                    aggregated_users[user_id] = {
                        'id': user_id, 'name': notification['name'],
                        'like_count': 0, 'collect_count': 0,
                        'follow_count': 0, 'comment_count': 0, # ãƒ•ã‚©ãƒ­ãƒ¼ã¨ã‚³ãƒ¡ãƒ³ãƒˆã®ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’è¿½åŠ 
                        'is_following': notification['is_following'],
                        'latest_action_timestamp': notification['action_timestamp']
                    }
                
                if "ã„ã„ã­ã—ã¾ã—ãŸ" in notification['action_text']:
                    aggregated_users[user_id]['like_count'] += 1
                if "ã‚³ãƒ¬ï¼ã—ã¾ã—ãŸ" in notification['action_text']:
                    aggregated_users[user_id]['collect_count'] += 1
                if "ã‚ãªãŸã‚’ãƒ•ã‚©ãƒ­ãƒ¼ã—ã¾ã—ãŸ" in notification['action_text']:
                    aggregated_users[user_id]['follow_count'] += 1
                if "ã‚ãªãŸã®å•†å“ã«ã‚³ãƒ¡ãƒ³ãƒˆã—ã¾ã—ãŸ" in notification['action_text']:
                    aggregated_users[user_id]['comment_count'] += 1

                if notification['action_timestamp'] > aggregated_users[user_id]['latest_action_timestamp']:
                    aggregated_users[user_id].update({
                        'is_following': notification['is_following'],
                        'latest_action_text': notification['action_text'],
                        'latest_action_timestamp': notification['action_timestamp']
                    })
            logging.info(f"  -> {len(aggregated_users)}äººã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«é›†ç´„ã—ã¾ã—ãŸã€‚")
            
            categorized_users = []
            for user in aggregated_users.values():
                like_count = user['like_count']
                is_following = user['is_following']
                follow_count = user['follow_count']
                collect_count = user['collect_count']
                
                if like_count >= 3:
                    user['category'] = "ã„ã„ã­å¤šè¬"
                elif follow_count > 0 and like_count > 0:
                    user['category'] = "æ–°è¦ãƒ•ã‚©ãƒ­ãƒ¼ï¼†ã„ã„ã­æ„Ÿè¬"
                elif like_count > 0 and not is_following: 
                    user['category'] = "æœªãƒ•ã‚©ãƒ­ãƒ¼ï¼†ã„ã„ã­æ„Ÿè¬"
                elif like_count > 0 and collect_count > 0:
                    user['category'] = "ã„ã„ã­ï¼†ã‚³ãƒ¬ï¼æ„Ÿè¬"
                elif follow_count > 0 and like_count == 0:
                    user['category'] = "æ–°è¦ãƒ•ã‚©ãƒ­ãƒ¼"
                elif like_count > 0:
                    user['category'] = "ã„ã„ã­æ„Ÿè¬"
                else:
                    user['category'] = "ãã®ä»–"
                
                # ã€Œãã®ä»–ã€ã‚«ãƒ†ã‚´ãƒªã¯å‡¦ç†å¯¾è±¡ã‹ã‚‰é™¤å¤–
                if user['category'] != "ãã®ä»–":
                    categorized_users.append(user)

            # --- ãƒ•ã‚§ãƒ¼ã‚º3: æ™‚é–“æ¡ä»¶ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ã€å„ªå…ˆåº¦é †ã«ã‚½ãƒ¼ãƒˆ ---
            logging.info(f"--- ãƒ•ã‚§ãƒ¼ã‚º3: æ™‚é–“æ¡ä»¶ã§ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ã¾ã™ã€‚ ---")
            
            # æ¡ä»¶è¨­å®š
            db_path = os.path.join(DB_DIR, DB_JSON_FILE)
            latest_db_timestamp = get_latest_timestamp_from_db(db_path)
            twelve_hours_ago = datetime.now() - timedelta(hours=12)
            
            logging.info(f"  - DBã®æœ€æ–°æ™‚åˆ»: {latest_db_timestamp.strftime('%Y-%m-%d %H:%M:%S') if latest_db_timestamp > datetime.min else 'ï¼ˆãƒ‡ãƒ¼ã‚¿ãªã—ï¼‰'}")
            logging.info(f"  - 12æ™‚é–“å‰ã®æ™‚åˆ»: {twelve_hours_ago.strftime('%Y-%m-%d %H:%M:%S')}")

            users_to_process = []
            for user in categorized_users:
                action_time = datetime.strptime(user['latest_action_timestamp'], '%Y-%m-%d %H:%M:%S')
                # æ¡ä»¶: 12æ™‚é–“ä»¥å†…ã§ã€ã‹ã¤DBã®æœ€æ–°æ™‚åˆ»ã‚ˆã‚Šæ–°ã—ã„
                if action_time > twelve_hours_ago and action_time > latest_db_timestamp:
                    users_to_process.append(user)
            
            logging.info(f"  -> {len(users_to_process)}äººã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå‡¦ç†å¯¾è±¡ã§ã™ã€‚")

            logging.info("å„ªå…ˆåº¦é †ã«ã‚½ãƒ¼ãƒˆã—ã¾ã™ã€‚")
            sorted_users = sorted(
                users_to_process,
                key=lambda u: (
                    -u['like_count'], # 1. ã„ã„ã­ã®æ•°ãŒå¤šã„ï¼ˆæœ€å„ªå…ˆï¼‰
                    -(u['follow_count'] > 0 and u['like_count'] > 0), # 2. æ–°è¦ãƒ•ã‚©ãƒ­ãƒ¼ï¼†ã„ã„ã­ãŒã‚ã‚‹
                    -(u['follow_count'] > 0 and u['like_count'] == 0), # 3. æ–°è¦ãƒ•ã‚©ãƒ­ãƒ¼ã®ã¿
                    u['is_following'], # 4. ãƒ•ã‚©ãƒ­ãƒ¼çŠ¶æ³
                    -(u['collect_count'] > 0) # 5. ã‚³ãƒ¬ï¼ãŒã‚ã‚‹
                )
            )
            
            # --- ãƒ•ã‚§ãƒ¼ã‚º4: URLå–å¾— ---
            logging.info(f"--- ãƒ•ã‚§ãƒ¼ã‚º4: {len(sorted_users)}äººã®ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«URLã‚’å–å¾—ã—ã¾ã™ã€‚ ---")
            final_user_data = []
            last_scroll_position = 0  # ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ä½ç½®ã‚’è¨˜æ†¶ã™ã‚‹å¤‰æ•°ã‚’åˆæœŸåŒ–

            for i, user_info in enumerate(sorted_users):
                logging.debug(f"  {i+1}/{len(sorted_users)}: ã€Œ{user_info['name']}ã€ã®URLã‚’å–å¾—ä¸­...")
                try:
                    # å‰å›ã®ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ä½ç½®ã«æˆ»ã™
                    if last_scroll_position > 0:
                        page.evaluate(f"window.scrollTo(0, {last_scroll_position})")
                        logging.debug(f"  ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ä½ç½®ã‚’ {last_scroll_position}px ã«å¾©å…ƒã—ã¾ã—ãŸã€‚")

                    user_li_locator = page.locator(f"li[ng-repeat='notification in notifications.activityNotifications']:has-text(\"{user_info['name']}\")").first
                    image_container_locator = user_li_locator.locator("div.left-img")
                    
                    max_scroll_attempts_find = 15
                    is_found = False
                    for attempt in range(max_scroll_attempts_find):
                        if image_container_locator.count() > 0 and image_container_locator.is_visible():
                            is_found = True
                            break
                        logging.debug(f"  ãƒ¦ãƒ¼ã‚¶ãƒ¼ã€Œ{user_info['name']}ã€ã®ç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã—ã¾ã™... ({attempt + 1}/{max_scroll_attempts_find})")
                        page.evaluate("window.scrollBy(0, 500)")
                        time.sleep(1)      

                    if not is_found:
                        raise PlaywrightError(f"ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã—ã¦ã‚‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã€Œ{user_info['name']}ã€ã®è¦ç´ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

                    # ãƒšãƒ¼ã‚¸é·ç§»ã®ç›´å‰ã«ç¾åœ¨ã®ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ä½ç½®ã‚’è¨˜æ†¶
                    last_scroll_position = page.evaluate("window.scrollY")
                    image_container_locator.click()
                    
                    user_info['profile_page_url'] = page.url
                    logging.debug(f"  -> å–å¾—ã—ãŸURL: {page.url}")
                    
                    page.go_back(wait_until="domcontentloaded")
                except Exception as url_error:
                    logging.warning(f"  ãƒ¦ãƒ¼ã‚¶ãƒ¼ã€Œ{user_info['name']}ã€ã®URLå–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {url_error}")
                    user_info['profile_page_url'] = "å–å¾—å¤±æ•—"
                
                final_user_data.append(user_info)
                time.sleep(0.5)

            logging.info("\n--- åˆ†æå®Œäº†: å‡¦ç†å¯¾è±¡ãƒ¦ãƒ¼ã‚¶ãƒ¼ä¸€è¦§ ---")
            for i, user in enumerate(final_user_data):
                logging.info(f"  {i+1:2d}. {user['name']:<20} (ã‚«ãƒ†ã‚´ãƒª: {user['category']}, URL: {user.get('profile_page_url', 'N/A')})")
            logging.info("------------------------------------")

            # --- ãƒ•ã‚§ãƒ¼ã‚º5: ã‚³ãƒ¡ãƒ³ãƒˆç”Ÿæˆ ---
            logging.info(f"--- ãƒ•ã‚§ãƒ¼ã‚º5: {len(final_user_data)}äººã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚³ãƒ¡ãƒ³ãƒˆã‚’ç´ä»˜ã‘ã¾ã™ã€‚ ---")
            try:
                with open(COMMENT_TEMPLATES_FILE, 'r', encoding='utf-8') as f:
                    comment_templates = json.load(f)
                
                for user in final_user_data:
                    category = user.get('category', 'ãã®ä»–')
                    templates = comment_templates.get(category, comment_templates.get('ãã®ä»–', []))
                    if templates:
                        comment_template = random.choice(templates)
                        natural_name = extract_natural_name(user.get('name', ''))
                        # åå‰ãŒå–å¾—ã§ãã€ã‹ã¤10æ–‡å­—ä»¥ä¸‹ã®å ´åˆã®ã¿åå‰ã‚’æŒ¿å…¥
                        if natural_name and len(natural_name) <= 6:
                            user['comment_text'] = comment_template.format(user_name=natural_name)
                        else:
                            # åå‰ãŒå–å¾—ã§ããªã‹ã£ãŸã‚Šé•·ã™ãã‚‹å ´åˆã¯ã€ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼éƒ¨åˆ†ã‚’å‰Šé™¤ã—ã¦ä¸è‡ªç„¶ã•ã‚’ãªãã™
                            user['comment_text'] = comment_template.replace("{user_name}ã•ã‚“ã€", "").strip()
                    else:
                        user['comment_text'] = "ã”è¨ªå•ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ï¼" # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            except FileNotFoundError:
                logging.error(f"ã‚³ãƒ¡ãƒ³ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {COMMENT_TEMPLATES_FILE}")
            except Exception as e:
                logging.error(f"ã‚³ãƒ¡ãƒ³ãƒˆç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

            # --- ãƒ•ã‚§ãƒ¼ã‚º6: çµæœã‚’æ—¢å­˜DBã¨ãƒãƒ¼ã‚¸ã—ã¦ä¿å­˜ ---
            try:
                os.makedirs(DB_DIR, exist_ok=True)
                db_path = os.path.join(DB_DIR, DB_JSON_FILE)

                # 1. æ—¢å­˜DBã‚’èª­ã¿è¾¼ã‚€
                existing_users = {}
                if os.path.exists(db_path):
                    try:
                        with open(db_path, 'r', encoding='utf-8') as f:
                            existing_data = json.load(f)
                            for user in existing_data:
                                if 'id' in user:
                                    existing_users[user['id']] = user
                    except (json.JSONDecodeError, FileNotFoundError):
                        logging.warning(f"æ—¢å­˜ã®DBãƒ•ã‚¡ã‚¤ãƒ«({db_path})ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚æ–°ã—ã„DBã‚’ä½œæˆã—ã¾ã™ã€‚")

                # 2. æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒ¼ã‚¸ï¼ˆæ–°ã—ã„æƒ…å ±ã§ä¸Šæ›¸ãï¼‰
                logging.info(f"--- ãƒ•ã‚§ãƒ¼ã‚º6: {len(final_user_data)}ä»¶ã®æ–°è¦ãƒ»æ›´æ–°ãƒ‡ãƒ¼ã‚¿ã‚’æ—¢å­˜DBã¨ãƒãƒ¼ã‚¸ã—ã¾ã™ã€‚ ---")
                for new_user in final_user_data:
                    existing_users[new_user['id']] = new_user

                # 3. 24æ™‚é–“ä»¥ä¸Šå‰ã®å¤ã„ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                logging.info("24æ™‚é–“ä»¥ä¸ŠçµŒéã—ãŸå¤ã„ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’DBã‹ã‚‰å‰Šé™¤ã—ã¾ã™ã€‚")
                twenty_four_hours_ago = datetime.now() - timedelta(hours=24)
                
                recent_users = []
                for user_data in existing_users.values():
                    action_time_str = user_data.get('latest_action_timestamp')
                    if action_time_str:
                        try:
                            action_time = datetime.strptime(action_time_str, '%Y-%m-%d %H:%M:%S')
                            if action_time >= twenty_four_hours_ago:
                                recent_users.append(user_data)
                        except ValueError:
                            logging.warning(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ '{user_data.get('name')}' ã®ä¸æ­£ãªæ—¥ä»˜å½¢å¼ã®ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’ã‚¹ã‚­ãƒƒãƒ—: {action_time_str}")

                # 4. ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¾Œã®ãƒ‡ãƒ¼ã‚¿ã‚’æœ€æ–°ã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ—¥æ™‚ã§é™é †ã‚½ãƒ¼ãƒˆã—ã¦ä¿å­˜
                final_data_to_save = sorted(recent_users, key=lambda u: u.get('latest_action_timestamp', ''), reverse=True)
                with open(db_path, 'w', encoding='utf-8') as f:
                    json.dump(final_data_to_save, f, ensure_ascii=False, indent=4)
                logging.info(f"ãƒãƒ¼ã‚¸ã¨ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å¾Œã®å…¨{len(final_data_to_save)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’ {db_path} ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")
            except Exception as e:
                logging.error(f"JSONãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®ä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

        except Exception as e:
            logging.error(f"å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}", exc_info=True)
            screenshot_path = os.path.join(OUTPUT_DIR, "error_screenshot.png")
            if 'page' in locals() and not page.is_closed(): page.screenshot(path=screenshot_path)
            logging.info(f"ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã‚’ {screenshot_path} ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")
        finally:
            logging.info("å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
            if 'page' in locals() and not page.is_closed():
                page.close()

if __name__ == "__main__":
    main()